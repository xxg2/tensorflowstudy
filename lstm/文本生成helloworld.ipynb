{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import collections\n",
    "import math\n",
    "import random\n",
    "import zipfile\n",
    "from matplotlib import pylab\n",
    "from six.moves import range\n",
    "from six.moves.urllib.request import urlretrieve\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件  select_description_from_sys_district.csv 已经存在.\n",
      "\n",
      "处理文件 datasets/select_description_from_sys_district.csv\n",
      "数据大小 (字符) (文档 0) 447415\n",
      "样本字符串 (文档 0) ['20', '19', '年开', '业6', '0间', '房。', '上海', '时生', '隅园', '林文', '化酒', '店：', '20', '17', '年的', '秋末', '，时', '生隅', '初见', '。彼', '时的', '心愿', '，想', '要在', '快节', '奏的', '都市', '，寻', '一处', '“讲', '诉时', '光和', '生命', '的角', '落”', '。不', '问对', '错，', '不闻', '浮沉', '。这', '便是', '“时', '生隅', '”的', '由来', '。 ', '这一', '次，', '我们']\n"
     ]
    }
   ],
   "source": [
    "dir_name = 'datasets'\n",
    "file_name = 'select_description_from_sys_district.csv'\n",
    "if not os.path.exists(dir_name+os.sep+file_name):\n",
    "    file_name = urlretrieve(url + file_name, dir_name+os.sep+file_name)\n",
    "else:\n",
    "    print('文件 ',file_name, '已经存在.')\n",
    "\n",
    "num_files = 1\n",
    "filenames = [file_name]\n",
    "def read_data(filename):\n",
    "  \n",
    "  with open(filename) as f:\n",
    "    data = tf.compat.as_str(f.read())\n",
    "    # 将所有文本均设为小写形式\n",
    "    data = data.lower()\n",
    "    data = list(data)\n",
    "  return data\n",
    "\n",
    "global documents\n",
    "documents = []\n",
    "for i in range(num_files):    \n",
    "    print('\\n处理文件 %s'%os.path.join(dir_name,filenames[i]))\n",
    "    chars = read_data(os.path.join(dir_name,filenames[i]))\n",
    "    \n",
    "    # 将文本分解成bigram形式\n",
    "    two_grams = [''.join(chars[ch_i:ch_i+2]) for ch_i in range(0,len(chars)-2,2)]\n",
    "    # 创建一个带有bigram形式的列表\n",
    "    documents.append(two_grams)\n",
    "    print('数据大小 (字符) (文档 %d) %d' %(i,len(two_grams)))\n",
    "    print('样本字符串 (文档 %d) %s'%(i,two_grams[:50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text: 894832 characters\n"
     ]
    }
   ],
   "source": [
    "text2 = open(dir_name+os.sep+file_name, 'rb').read().decode(encoding='utf-8')\n",
    "\n",
    "# 文本长度是指文本中的字符个数\n",
    "print ('Length of text: {} characters'.format(len(text2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019年开业60间房。上海时生隅园林文化酒店：2017年的秋末，时生隅初见。彼时的心愿，想要在快节奏的都市，寻一处“讲诉时光和生命的角落”。不问对错，不闻浮沉。这便是“时生隅”的由来。 这一次，我们秉承初心，在闹中取静的川沙地铁站商圈，觅得一方天地—充满江南气息的园林，叶园。长廊湖景，古雅庭院。这里淡雅而大气，是快节奏与民俗文化的交融，这里幽静而明快，是远道而来亦或小憩而居的别样天地。时生隅的新老朋友，我们在叶园，期待与您共襄当下景，把时光言欢。\n",
      "2018年开业2018年装修143间房。云和夜泊酒店(上\n"
     ]
    }
   ],
   "source": [
    "print(text2[:255])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3014 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text2))\n",
    "print ('{} unique characters'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  '\\n':   0,\n",
      "  ' ' :   1,\n",
      "  '!' :   2,\n",
      "  '\"' :   3,\n",
      "  '%' :   4,\n",
      "  '&' :   5,\n",
      "  \"'\" :   6,\n",
      "  '(' :   7,\n",
      "  ')' :   8,\n",
      "  '*' :   9,\n",
      "  '+' :  10,\n",
      "  ',' :  11,\n",
      "  '-' :  12,\n",
      "  '.' :  13,\n",
      "  '/' :  14,\n",
      "  '0' :  15,\n",
      "  '1' :  16,\n",
      "  '2' :  17,\n",
      "  '3' :  18,\n",
      "  '4' :  19,\n",
      "  ...\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print('{')\n",
    "for char,_ in zip(char2idx, range(20)):\n",
    "    print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))\n",
    "print('  ...\\n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "0\n",
      "1\n",
      "9\n",
      "年\n"
     ]
    }
   ],
   "source": [
    "# 设定每个输入句子长度的最大值\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(text2)//seq_length\n",
    "\n",
    "# 创建训练样本 / 目标\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(5):\n",
    "  print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'2019年开业60间房。上海时生隅园林文化酒店：2017年的秋末，时生隅初见。彼时的心愿，想要在快节奏的都市，寻一处“讲诉时光和生命的角落”。不问对错，不闻浮沉。这便是“时生隅”的由来。 这一次，我们秉'\n",
      "'承初心，在闹中取静的川沙地铁站商圈，觅得一方天地—充满江南气息的园林，叶园。长廊湖景，古雅庭院。这里淡雅而大气，是快节奏与民俗文化的交融，这里幽静而明快，是远道而来亦或小憩而居的别样天地。时生隅的新老朋'\n",
      "'友，我们在叶园，期待与您共襄当下景，把时光言欢。\\n2018年开业2018年装修143间房。云和夜泊酒店(上海浦东国际机场店)，位于浦东新区祝桥秋亭路，毗邻上海浦东国际机场，车程20分钟，距上海迪士尼18'\n",
      "'分钟车程，距上海野生动物园21分钟车程。酒店地理位置优越，并配备大巴、中巴、豪华轿车接送客户。酒店拥有房间98间，大床30间，行政大床15间，标间30间，亲子房23间。\\n2015年开业2017年装修23'\n",
      "'6间房。维也纳酒店（上海浦东机场店）位于浦东新区川南奉公路，近晨阳路，与迪士尼直线距离约8公里，可便捷到达地铁2号线凌空路站，交通便利。酒店周围生活设施齐全，旅游资源众多，有上海新国际博览中心、迪士尼、'\n",
      "'上海野生动物园、农艺大观园、三甲港滨海旅游区等。\\u3000\\u3000维也纳酒店（上海浦东机场店）是维也纳旗下的连锁酒店，装修豪华舒适，整体风格高贵典雅。客房宽敞明亮、温馨时尚，房内布置精美，处处体现人性化的理念。\\u3000\\u3000酒'\n",
      "'店还有宽敞停车场、休闲茶吧、宽敞会议室等，同时还为您提供精品早餐、浦东机场接机（需预约）等服务，是商务、休闲、会务的理想酒店。\\n2018年开业194间房。上海万信R酒店位于浦东新区崮山路，地处内环线陆家'\n",
      "'嘴金融区内，近地铁6号线（北洋泾路站），地铁9号线（芳甸路站），配备专属停车场，自驾至新国际博览中心约10分钟，至外滩、世博园区、南京路步行街、上海自由贸易区、上海迪斯尼乐园约20分钟。\\u3000\\u3000\\u3000\\u3000酒店拥有'\n",
      "'百余间崭新客房，精选配套，让舒适与轻奢相拥；酒店圣罗拉餐厅环境舒适安逸，主打西餐、辅以粤菜、川菜、沪菜，在此享受由港粤名厨精心烹饪的佳肴，舌尖不由自主的跳起了芭蕾。早餐的菜品琳琅满目可达40种，为保证口'\n",
      "'味，餐品均选优质食材当天加工。\\u3000\\u3000\\u3000\\u3000酒店豪华宴会厅提供一站式婚礼服务与专业的会务服务。200㎡万信厅可支持约120人课桌式会议，100㎡丽都厅适合60人以下的各类会议需求。\\u3000\\u3000\\u3000\\u3000万信R酒店设计，突破'\n",
      "'了“万信酒店”一贯理念，时尚年轻，秉承R文化，华丽，贴心，轻松，享受。\\n\"2017年开业2019年装修151间房。酒店位于浦东新区沪南公路3655弄2号，素有小上海之称的周浦镇，沪南公路横桥路路口，周边'\n",
      "'有地铁16号线周浦东站及11号线秀沿路站，16号线可直达海洋公园，冰雪世界等游玩景点，11号线可直达迪士尼乐园；毗邻迪士尼乐园、新国际博览中心。酒店周围有迪士尼，上海野生动物园，海昌海洋世界，上海科技馆'\n",
      "'等多个游玩景点，周边更有万达广场，绿地商城，美食、娱乐均可轻松满足。酒店由美国著名设计师打造，是知名高端“设计师酒店”品牌。客房典雅豪华、宽敞舒适，并配以42寸飞利浦电视、三诺音响、电动窗帘、智能灯控系'\n",
      "'统等先进科技设施设备，带来尊贵体验和高端享受。酒店每个房间都有独立的企业级WIFI,带给您网络的极速体验，这里的隔音系统更由清华声学所设计，睡眠环境优越，让你一夜酣眠。酒店提供浦东国际机场，迪士尼和周浦'\n",
      "'东站的定时免费班车服务（请提前一天致电酒店前台预约，详情请咨询店家。）。\"\\n2018年开业195间房。唯庭酒店(上海外滩店)位于黄浦区中山南路，靠近董家渡轻纺市场、南浦大桥，与豫园、外滩、人民广场、老西'\n",
      "'门以及南京东路步行街相邻，靠近十六铺码头，体验老上海风情的历史风光，周边交通便利，与4号线，9号线相近，可步行至豫园。\\u3000\\u3000酒店设有两百余间不同类型的客房，房内均配备智能控制系统、高级床品和高端洗浴用品，'\n",
      "'酒店独有会议室、早餐厅一应俱全。酒店以现代轻奢风，精致时尚的环境、智能及舒适人性的客房、高效便捷的设施以及温馨细致的服务，带给您一场全新的商务旅行体验线。\\n2019年开业2019年装修98间房。上海迪漫'\n",
      "'酒店位于上海浦东新区川沙镇——川图路，地处迪士尼乐园旁核心位置，距离迪士尼约3公里左右，2号地铁站川沙站约3.5公里。 酒店监控区域内有停车位，房间内配备24小时热水、拖鞋、独立淋浴间、吹风机、洗漱用品'\n",
      "'，以及书桌、液晶电视、高速上网、空调、WIFI、电水壶等。 此外，酒店有专车接送服务（详情请咨询商家），酒店保证为每一位顾客提供优质的服务，全面的设施，迪漫酒店期待您的光临。\\n2018年开业188间房。'\n",
      "'酒店位于南京路步行街中心位置、地处南京路步行街上，毗邻人民广场、杜莎夫人蜡像馆、城隍庙、豫园、外滩、淮海路商圈、隔江眺望东方明珠、环球金融中心。从酒店步行可至地铁1、2、8的人民广场站5、6、19号出口'\n",
      "'以及10号线南京东路站1号口、交通便利。酒店客房内设有先进的智能化客房电子设备、精致时尚的住宿环境、舒适人性的客房、高效便捷的设施、恰到好处的服务，带您体验商务旅行新乐趣。让您拥有惬意的住宿环境，享受每'\n",
      "'一段自在旅程。\\n2018年开业2019年装修73间房。上海沪迪酒店位于上海市浦东新区川图路，与川沙路交汇处，距迪士尼直线距离约1.9公里，地铁站约5分钟车程，酒店周边景点有上海科技馆、上海野生动物园、佛'\n",
      "'罗伦萨小镇、东方明珠、外滩、南京路步行街。\\u3000\\u3000酒店面积近万平米，配有24小时全家便利店，餐厅、足浴SP、会议室等，酒店装修风格以北欧风、美式风及儿童亲子风格为主，无论您游玩迪士尼还是出行浦东机场，上海沪'\n",
      "'迪酒店是您不错选择。\\u3000\\u3000酒店还提供免费接送迪士尼、浦东机场、2号线地铁川沙站（详情请咨询商家）。\\n\"2019年开业120间房。上海迪堡王国酒店位于上海浦东新区川沙镇——川图路，地处迪士尼乐园旁核心位置，'\n",
      "'距离迪士尼约3公里左右，2号地铁站川沙站约3.5公里。 酒店监控区域内有停车位，房间内配备24小时热水、拖鞋、独立淋浴间、吹风机、洗漱用品，以及书桌、液晶电视、高速上网、空调、WIFI、电水壶等。 此外'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(25):\n",
    "  print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data:  '2019年开业60间房。上海时生隅园林文化酒店：2017年的秋末，时生隅初见。彼时的心愿，想要在快节奏的都市，寻一处“讲诉时光和生命的角落”。不问对错，不闻浮沉。这便是“时生隅”的由来。 这一次，我们'\n",
      "Target data: '019年开业60间房。上海时生隅园林文化酒店：2017年的秋末，时生隅初见。彼时的心愿，想要在快节奏的都市，寻一处“讲诉时光和生命的角落”。不问对错，不闻浮沉。这便是“时生隅”的由来。 这一次，我们秉'\n"
     ]
    }
   ],
   "source": [
    "for input_example, target_example in  dataset.take(1):\n",
    "  print ('Input data: ', repr(''.join(idx2char[input_example.numpy()])))\n",
    "  print ('Target data:', repr(''.join(idx2char[target_example.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step    0\n",
      "  input: 17 ('2')\n",
      "  expected output: 15 ('0')\n",
      "Step    1\n",
      "  input: 15 ('0')\n",
      "  expected output: 16 ('1')\n",
      "Step    2\n",
      "  input: 16 ('1')\n",
      "  expected output: 24 ('9')\n",
      "Step    3\n",
      "  input: 24 ('9')\n",
      "  expected output: 938 ('年')\n",
      "Step    4\n",
      "  input: 938 ('年')\n",
      "  expected output: 972 ('开')\n"
     ]
    }
   ],
   "source": [
    "for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n",
    "    print(\"Step {:4d}\".format(i))\n",
    "    print(\"  input: {} ({:s})\".format(input_idx, repr(idx2char[input_idx])))\n",
    "    print(\"  expected output: {} ({:s})\".format(target_idx, repr(idx2char[target_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 批大小\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 设定缓冲区大小，以重新排列数据集\n",
    "# （TF 数据被设计为可以处理可能是无限的序列，\n",
    "# 所以它不会试图在内存中重新排列整个序列。相反，\n",
    "# 它维持一个缓冲区，在缓冲区重新排列元素。） \n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 词集的长度\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# 嵌入的维度\n",
    "embedding_dim = 256\n",
    "\n",
    "# RNN 的单元数量\n",
    "rnn_units = 1024\n",
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "  model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                              batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "  ])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "  vocab_size = len(vocab),\n",
    "  embedding_dim=embedding_dim,\n",
    "  rnn_units=rnn_units,\n",
    "  batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 3014) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "  example_batch_predictions = model(input_example_batch)\n",
    "  print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (64, None, 256)           771584    \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 3014)          3089350   \n",
      "=================================================================\n",
      "Total params: 7,799,238\n",
      "Trainable params: 7,799,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 3014)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       8.011231\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss  = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)\n",
    "# 检查点保存至的目录\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "\n",
    "# 检查点的文件名\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 138 steps\n",
      "Epoch 1/10\n",
      "138/138 [==============================] - 267s 2s/step - loss: 5.3146\n",
      "Epoch 2/10\n",
      "138/138 [==============================] - 250s 2s/step - loss: 3.3793\n",
      "Epoch 3/10\n",
      "138/138 [==============================] - 239s 2s/step - loss: 2.8448\n",
      "Epoch 4/10\n",
      "138/138 [==============================] - 233s 2s/step - loss: 2.5451\n",
      "Epoch 5/10\n",
      "138/138 [==============================] - 233s 2s/step - loss: 2.3327\n",
      "Epoch 6/10\n",
      "138/138 [==============================] - 233s 2s/step - loss: 2.1595\n",
      "Epoch 7/10\n",
      "138/138 [==============================] - 491s 4s/step - loss: 2.0118\n",
      "Epoch 8/10\n",
      "138/138 [==============================] - 261s 2s/step - loss: 1.8756\n",
      "Epoch 9/10\n",
      "138/138 [==============================] - 249s 2s/step - loss: 1.7486\n",
      "Epoch 10/10\n",
      "138/138 [==============================] - 256s 2s/step - loss: 1.6311\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=10\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            771584    \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1024)           3938304   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 3014)           3089350   \n",
      "=================================================================\n",
      "Total params: 7,799,238\n",
      "Trainable params: 7,799,238\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "靠近 著名品牌“古玲玉兰””——炮上餐厅、国际房内等游玩客房，是美味锻炼的好去处。酒店设有站式餐厅，可以满足旅客的需求，更有高速的无线网络，特惠房间床，配备有洗衣架和4间，酒店客房均全网落地窗，透过不足门口。\n",
      "2015年开业2013年装修33间房。99旅馆连锁(上海五代中心地铁站店)位于黄浦区打浦江新城路4号门斜对面靠近35路梅南路口，旁，地理罗山路之内，紧靠人民广场、南京路步行街等旅游景点，仅15分钟可到。酒店地处于上海松江团队带，周边围绕着名设计，营业丰富特色共商业氛围，更有近百安购物中心。　　海友客栈（上海徐家汇繁华客房，房内设有浴室独立空调、独立空调、电视、24小时热水等设施，无线网络全覆盖，为您营造安全、舒适、住宿的温暖。\n",
      "2019年开业198间房。汉庭酒店（上海共平路店）处黄浦江中心，地处地铁四号线中山北路站南广场，交通极其便利，是尽外，驱车至闵行体育公园仅5分钟、三、好地玻璃窗、沐浴露和用品(p记))、高星级品牌旗下服务，酒店灵魂提倡人们需要及提供标准服务和免费停车问等，是您商务旅行之家的宾客商务.无论您与异体验探索机场。　　铂·无线wifi，独立冷暖空调、有烤线光纤上网、电量，还有高架机和开接待朋友酒店的处领名的上海旅游区域，是你在浦东休闲的住宿环境，流连忘返入住酒店，前台交通是您放松游休闲的亲切身处。\n",
      "2018年开业57间房。89旅馆连锁（上海交大店）位于上海市宝山区沪太路水产村，毗邻金桥进口工业园区，东靠汽车南路，致力于为追求商务客人提供宽带上网，纵体的外滩风景区域；3分钟的车程即可从到达酒店；G60沪昆高速江北路2016等交通便捷。地理位置优越，交通便利。\n",
      "2019年开业36间房。贝壳酒店(上海五角场店)坐落于环境优越的临近相连路店)毗邻七宝老街、上海迪士尼度假区东明公园、仁济医院。 酒店客房设计凸显《云翔裸温摄餐》还提供细致每一让回家的到来，您在爱揽这望自在这一靠宁静。\n",
      "2008年开业2017年装修102间房。上海三甲港凯悦酒店位于黄浦区长江南路（陆盛路口往人民广场步行街涞科路淀山西路，西藏北路地铁站即可前往。\n",
      "2012年开业2016年装修142间房。汉庭酒店（上海火车站店）位于中国北路，距上海火车站可乘坐15号线至国家会展中心约40分钟，到上海著名的“七宝”街仅需25分钟车程。酒店上海素重装修为华住宗旨，倾注为「神咖啡」，清爽真溢艺术“A级”为主\n"
     ]
    }
   ],
   "source": [
    "def generate_text(model, start_string):\n",
    "  # 评估步骤（用学习过的模型生成文本）\n",
    "\n",
    "  # 要生成的字符个数\n",
    "  num_generate = 1000\n",
    "\n",
    "  # 将起始字符串转换为数字（向量化）\n",
    "  input_eval = [char2idx[s] for s in start_string]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  # 空字符串用于存储结果\n",
    "  text_generated = []\n",
    "\n",
    "  # 低温度会生成更可预测的文本\n",
    "  # 较高温度会生成更令人惊讶的文本\n",
    "  # 可以通过试验以找到最好的设定\n",
    "  temperature = 1.0\n",
    "\n",
    "  # 这里批大小为 1\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # 删除批次的维度\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # 用分类分布预测模型返回的字符\n",
    "      predictions = predictions / temperature\n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # 把预测字符和前面的隐藏状态一起传递给模型作为下一个输入\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "      text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "  return (start_string + ''.join(text_generated))\n",
    "print(generate_text(model, start_string=u\"靠近 \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
