{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "import reader\n",
    "import os\n",
    "import pydot_ng\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文件  select_description_from_sys_district.csv 存在。盛宴大幕拉开了。\n",
      "段落处理完毕\n"
     ]
    }
   ],
   "source": [
    "file_name = 'select_description_from_sys_district.csv'\n",
    "if reader.check_file(file_name, url=''):\n",
    "    hotelDescs = reader.read_data_as_array(file_name)\n",
    "else:\n",
    "    quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3520\n",
      "2018年开业2018年装修143间房。云和夜泊酒店(上海浦东国际机场店)，位于浦东新区祝桥秋亭路，毗邻上海浦东国际机场，车程20分钟，距上海迪士尼18分钟车程，距上海野生动物园21分钟车程。酒店地理位置优越，并配备大巴、中巴、豪华轿车接送客户。酒店拥有房间98间，大床30间，行政大床15间，标间30间，亲子房23间。\n"
     ]
    }
   ],
   "source": [
    "print(len(hotelDescs))\n",
    "print(hotelDescs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "有3014个不重复字符\n"
     ]
    }
   ],
   "source": [
    "hotelText = reader.read_data_as_text(file_name)\n",
    "vocab = sorted(set(hotelText))\n",
    "vocab_size = len(vocab)\n",
    "print('有{}个不重复字符'.format(len(vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "hotelText_as_int = np.array([char2idx[c] for c in hotelText])\n",
    "\n",
    "#for char, _ in zip(char2idx, range(10)):\n",
    "#    print('{:4s}: {:3d}'.format(repr(char), char2idx[char]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 894831 个单词.\n",
      "常用的词 (+UNK) [('，', 33827), ('、', 22474), ('。', 17855), ('的', 16469), ('店', 14173)]\n",
      "不常用的词 (+UNK) [('棒', 1), ('瓢', 1), ('俚', 1), ('狼', 1), ('猬', 1), ('涨', 1), ('℃', 1), ('催', 1), ('厘', 1), ('逢', 1), ('庠', 1), ('剥', 1), ('｡', 1), ('辨', 1), ('蔼', 1)]\n",
      "样本数据 [11]\n",
      "样本数据 [6]\n",
      "词汇量:  2155\n"
     ]
    }
   ],
   "source": [
    "def build_dataset(documents):\n",
    "    chars = []\n",
    "    # 这是一些列表．外部列表表示每个文档,内部列表表示给定文档中的单词     \n",
    "    data_list = []\n",
    "  \n",
    "    for d in documents:\n",
    "        chars.extend(d)\n",
    "    print('找到 %d 个单词.'%len(chars))\n",
    "    count = []\n",
    "    # 根据频率对bigram进行排序（最高的排在第一位）\n",
    "    count.extend(collections.Counter(chars).most_common())\n",
    "    \n",
    "    # 通过给出字典的当前长度为每个bigram创建一个ID\n",
    "    # 并将该元素添加到字典中\n",
    "    # 从分配给文本中稀有单词的“UNK”开始    \n",
    "    dictionary = dict({'UNK':0})\n",
    "    for char, c in count:\n",
    "        # 如果统计的频率超过10，则仅增加一个bigram到字典中\n",
    "        if c > 4:\n",
    "            dictionary[char] = len(dictionary)    \n",
    "    \n",
    "    unk_count = 0\n",
    "    # 遍历所有文本,我们将每个字符串形式的单词替换为单词的ID     \n",
    "    for d in documents:\n",
    "        data = list()\n",
    "        for char in d:\n",
    "            # 如果一个单词存在于词典中,则使用该单词ID,否则使用特殊标记“UNK”的ID            \n",
    "            if char in dictionary:\n",
    "                index = dictionary[char]        \n",
    "            else:\n",
    "                index = dictionary['UNK']\n",
    "                unk_count += 1\n",
    "            data.append(index)\n",
    "            \n",
    "        data_list.append(data)\n",
    "        \n",
    "    reverse_dictionary = dict(zip(dictionary.values(), dictionary.keys())) \n",
    "    return data_list, count, dictionary, reverse_dictionary\n",
    "\n",
    "global data_list, count, dictionary, reverse_dictionary,vocabulary_size\n",
    "\n",
    "# 打印数据一些的统计信息\n",
    "data_list, count, dictionary, reverse_dictionary = build_dataset(hotelText)\n",
    "print('常用的词 (+UNK)', count[:5])\n",
    "print('不常用的词 (+UNK)', count[-15:])\n",
    "print('样本数据', data_list[0][:10])\n",
    "print('样本数据', data_list[1][:10])\n",
    "print('词汇量: ',len(dictionary))\n",
    "vocabulary_size = len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for hotelDesc in hotelDescs:\n",
    "    seq_length = len(hotelDesc)\n",
    "    example_per_epoch = len(hotelText) // seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          192896    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               98816     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 293,002\n",
      "Trainable params: 293,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "# Add an Embedding layer expecting input vocab of size 1000, and\n",
    "# output embedding dimension of size 64.\n",
    "model.add(layers.Embedding(input_dim=vocab_size, output_dim=64))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units and softmax activation.\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvocationException",
     "evalue": "GraphViz's executables not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mInvocationException\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-28e5ed4d6daa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir, expand_nested, dpi)\u001b[0m\n\u001b[1;32m    281\u001b[0m                      \u001b[0mrankdir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrankdir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m                      \u001b[0mexpand_nested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexpand_nested\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m                      dpi=dpi)\n\u001b[0m\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir, expand_nested, dpi, subgraph)\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'IPython.core.magics.namespace'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0;31m# We don't raise an exception here in order to avoid crashing notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mcheck_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Attempt to create an image of a blank graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pydot_ng/__init__.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format)\u001b[0m\n\u001b[1;32m   1819\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1820\u001b[0m                 raise InvocationException(\n\u001b[0;32m-> 1821\u001b[0;31m                     'GraphViz\\'s executables not found')\n\u001b[0m\u001b[1;32m   1822\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1823\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprog\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvocationException\u001b[0m: GraphViz's executables not found"
     ]
    }
   ],
   "source": [
    "#tf.keras.utils.plot_model(model, 'a.png')  出不来"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
